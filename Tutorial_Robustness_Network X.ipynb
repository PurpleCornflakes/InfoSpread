{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authors: [Michael Lees](http://www.mhlees.com), Debraj Roy\n",
    "\n",
    "---\n",
    "The MIT License (MIT)\n",
    "\n",
    "Copyright (c) 2015 Michael Lees, Debraj Roy\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "\n",
    "---\n",
    "# Robustness\n",
    "\n",
    "Networks occur in many natural and man-made systems, including Financial Systems, Computer Systems (like the WWW and the Internet), Biological Systems (the brain, protein networks, etc.) and Social Systems (e.g., contact networks). Understanding something about the robustness of these networks, in the case of when nodes or edges are removed, is important if we want to engineer or protect these systems.\n",
    "\n",
    "For further reading please refer to Chapter 8 of the free Barabási E-book (http://barabasi.com/networksciencebook/content/book_chapter_8.pdf)\n",
    "\n",
    "In this exercise we will recreate the experiments of Albert, Jeong and Barabási. You can see the paper at http://www.nature.com/nature/journal/v406/n6794/full/406378a0.html\n",
    "\n",
    "We will analyse a number of artificial and real world networks in terms of their robustness to *failures* and *attacks*. We define a *failure* in a network as the *random* removal of a node (and its connected edges), whereas an *attack* is when we specifically remove targeted nodes (and their connected edges) based on some measure (e.g., max degree, max betweenness, etc.).\n",
    "\n",
    "The attacks (or failures) are made one-by-one to the network until we remove a fraction $f$ of all the nodes $N$ in the original network. We then measure a number of network parameters to gauge their impact as a function of $f$: \n",
    "    \n",
    "1. $S_c$, fraction of remaining nodes in the largest component\n",
    "2. $<l>_c$, average path length of largest component\n",
    "3. $D_c$, Diameter of the largest component \n",
    "\n",
    "We will conduct these experiments on a number of networks, Barabási-Albert (BA) networks, Erdös-Réyni (ER) networks and the airline network from the previous exercise. Of course, in the case of the artificial networks we will want to repeat the analysis for many parameters and many instanes of the networks, so this may require significant computation. For reference see the figure below, also from Barabási. These graphs show the robustness of BA (scale-free) and ER networks, the top two graphs show $S$ the fraction of nodes in the giant component as a function of removals, circles are attacks and squares are failures. The lower two figures show average path length $<l>$ as a function of removals. The left hand graphs show ER networks and the right hand graphs show BA networks.\n",
    "\n",
    "<img src=\"robustness.png\"width=\"600\"></img>\n",
    "\n",
    "## Robustness, good or bad?\n",
    "\n",
    "Generally you might think of more robustness networks as a good thing. However, sometimes we would like networks to be less robust, or figure out the best way to make the network fail. A good example of this is when you are deciding who to vacinate against a particular disease given a social contact network. A vacination is effectively the removal of a specific node in the contact network as this person cannot get or transmit the disease to others. If you're very careful, and very lucky, you might be able to break the network apart by strategically attacking (vacinating) only a few nodes.\n",
    "\n",
    "Airport networks are crucial for understanding the spread of world-wide pandemics. Air-travel is one of the quickest ways that diseases can spread across the globe. For the airport network, an attack is effectively the closure of an airport. In that case we want to find out if it's possible to break the network apart, and stop the disease spread, by only attacking a few nodes (closing a few airports).\n",
    "\n",
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx #import NetworkX\n",
    "import numpy as np #import numpy for ...\n",
    "#force drawing of graphs inline for ipython notebook\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt #import matplotlib for plotting/drawing grpahs\n",
    "import matplotlib.patches as mpatches #for legends in the graph\n",
    "from __future__ import unicode_literals #allow UTF characters in graph labels\n",
    "import random # for random choice function\n",
    "import copy # this is use for making deep copies of lists\n",
    "from tqdm import tqdm #nice library for progress bars\n",
    "import sys #for writing output to stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our attack and fail functions\n",
    "\n",
    "We now define 3 Python functions that we can use to remove nodes, either attacks of failures. We will use these functions repeatedly to affect the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fail(G): #a python function that will remove a random node from the graph G\n",
    "    n = random.choice(G.nodes())  #pick a random node\n",
    "    G.remove_node(n) # remove that random node, attached edges automatically removed.\n",
    "    \n",
    "def attack_degree(G): #remove node with maximum degree\n",
    "    degrees = G.degree() # get dcitonary where key is node id, value is degree\n",
    "    max_degree = max(degrees.values()) # find maximum degree value from all nodes\n",
    "    max_keys = [k for k,v in degrees.items() if v==max_degree] #get all nodes who have the maximum degree (may be more than one)\n",
    "    G.remove_node(max_keys[0]) #remove just the first node with max degree, we will remove others next\n",
    "    \n",
    "def attack_betweenness(G): #note - not currently used, but try it!\n",
    "    betweenness = nx.betweenness_centrality(G) # get dictionary where key is node id and value is betweenness centrality\n",
    "    max_betweenenss = max(betweenness.values()) # find maximum degree value from all nodes\n",
    "    max_keys = [k for k,v in betweenness.items() if v==max_betweenness] #get all nodes who have the maximum degree (may be more than one)\n",
    "    G.remove_node(max_keys[0]) #remove just the first node with max degree, we will remove others next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Networks\n",
    "\n",
    "Now we will generate a number of different networks using the in built NetworkX methods. Each of these network generators has a number of parameters (including network size), we will vary these somewhat to test their impact. However, it's advisable avoid doing networks which are very large as this will take too much time.\n",
    "\n",
    "### Experiment parameters ###\n",
    "\n",
    "Below are the parametes we will use to create the artificial networks (for the experiments) and other experimental parameters. Change these if you want to run with different network configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NetworkSize = 1000 #network size to use in experiments\n",
    "ba_m = [3] #list of m values to use, m indicate the number of new edges to add for every new node added in the BA model\n",
    "p_values = [0.008] #p values to use for ER networks, p indicates probability of making an edge\n",
    "repetitions = 1 #For each of the parameter settings above, how many unqiue graphs do we want to generate.\n",
    "\n",
    "fraction_of_nodes_to_remove = 0.95 # remove until this fraction of all original nodes are removed\n",
    "num_removals = int(fraction_of_nodes_to_remove * NetworkSize) #number of nodes to remove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the artificial networks\n",
    "\n",
    "Below we create our artificial networks and store them in two lists. We also make a deep copy, so we can re-use them whenever necessary. Don't forget, the experiments will actually destroy the networks by removing nodes, so in case we want to run the fail on *exactly* the same network as the attacks, we need to have a copy to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_networks = [] #list to store BA networks,\n",
    "er_networks = [] #list to store ER networks,\n",
    "    \n",
    "for m in ba_m: #create BA networks\n",
    "    for r in range(repetitions):\n",
    "        ba_networks.append(nx.barabasi_albert_graph(NetworkSize, m, r))\n",
    "\n",
    "for p in p_values: #create ER networks\n",
    "    for r in range(repetitions):\n",
    "        er_networks.append(nx.erdos_renyi_graph(NetworkSize, p, r))\n",
    "    \n",
    "orig_er_networks = copy.deepcopy(er_networks) # make copies of the network lists a deep copy will copy the list and the items inside.\n",
    "orig_ba_networks = copy.deepcopy(ba_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Original Network statistics\n",
    "\n",
    "We now have some BA networks and some ER networks that we can analyse, we will measure the diameter $D$, the average path  length $<l>$ and the fraction of nodes in the giant component (although this will be 1.0 initially for the BA networks)\n",
    "\n",
    "First we get all metrics for the BA networks, you'll notice the diameter is typically the same, and the average path length varies a little.\n",
    "\n",
    "To make this more effecient we create a few functions. First we make a function that calculates the diameter and average path length at the same time (this is more effecient than doing both separately).\n",
    "\n",
    "We then have a function for collecting the statistics in a single graph, then another function for collecting statistics from a list of graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diameter_ave_path_length(G):\n",
    "    # We create our own function to do this so things are slightly faster, \n",
    "    # we can calculate diameter and avg path length at the same time\n",
    "    max_path_length = 0\n",
    "    total = 0.0\n",
    "    for n in G: #iterate over all nodes\n",
    "        path_length=nx.single_source_shortest_path_length(G, n) # generate shortest paths from node n to all others\n",
    "        total += sum(path_length.values()) #total of all shortest paths from n\n",
    "        if max(path_length.values()) > max_path_length: #keep track of longest shortest path we see.\n",
    "            max_path_length = max(path_length.values())         \n",
    "    try:\n",
    "        avg_path_length = total / (G.order()*(G.order() - 1))\n",
    "    except ZeroDivisionError:\n",
    "        avg_path_length = 0.0\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def all_network_statistics(nw_list): \n",
    "    # a function that takes in a list of networks and returns 3 lists of same length listing the diameter, average \n",
    "    # path length and giant component size for all the networks\n",
    "    diameters = []\n",
    "    path_lengths = []\n",
    "    S = []\n",
    "    for n in nw_list:\n",
    "        d,l,s = a_network_statistics(n)\n",
    "        diameters.append(d)\n",
    "        path_lengths.append(l)\n",
    "        S.append(s)\n",
    "    return (diameters, path_lengths, S)\n",
    "\n",
    "def a_network_statistics(n):\n",
    "    \n",
    "    Gcc=sorted(nx.connected_component_subgraphs(n), key = len, reverse=True)\n",
    "    G0=Gcc[0]\n",
    "    d,l = diameter_ave_path_length(G0)\n",
    "    s = float(G0.order()) / float(NetworkSize)\n",
    "    return d,l,s\n",
    "\n",
    "print all_network_statistics(ba_networks) #calculate and print all statistics of the BA networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same thing for the ER networks, notice that the value of p=0.08 was selected to create networks with approximately the same average path length as the BA model with m=3. From analytical results we know that $$<l>_{ER} = \\frac{\\ln(N)}{\\ln(N \\times p)}$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print all_network_statistics(er_networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Failures\n",
    "\n",
    "Now we will gradually fail our BA and ER Networks.\n",
    "\n",
    "Note that these calculations take a significant amount of time, because after each failure, and for each network we measure the diameter and average path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This is needed if we just want to rerun this cell and not have to create the networks again after we destroy them\n",
    "er_networks = copy.deepcopy(orig_er_networks)\n",
    "ba_networks = copy.deepcopy(orig_ba_networks)\n",
    "\n",
    "\n",
    "\n",
    "def experiments(networks, removals, run_fail=True, measure_every_X_removals=20):\n",
    "    # the below list will record the average statistic for all networks, a new entry in the list is added after each fail\n",
    "    ave_diameters = []\n",
    "    ave_path_lengths = []\n",
    "    ave_S = []\n",
    "    sys.stderr.write(\"---- Starting Experiments ---- \\n\")\n",
    "    sys.stderr.flush()\n",
    "    for x in tqdm(range(removals)):                    \n",
    "        for n in networks:\n",
    "            if run_fail:\n",
    "                fail(n)\n",
    "            else:\n",
    "                attack_degree(n)\n",
    "        if x % measure_every_X_removals == 0:            \n",
    "            d, l, s = all_network_statistics(networks)\n",
    "            ave_diameters.append(np.mean(d))\n",
    "            ave_path_lengths.append(np.mean(l))\n",
    "            ave_S.append(np.mean(s))\n",
    "    sys.stderr.write(\"---- Experiments Finished ---- \\n\")\n",
    "    sys.stderr.flush()\n",
    "    return ave_diameters, ave_path_lengths, ave_S\n",
    "                \n",
    "er_ave_diameters, er_ave_path_lengths, er_ave_S = experiments(er_networks, num_removals)\n",
    "ba_ave_diameters, ba_ave_path_lengths, ba_ave_S = experiments(ba_networks, num_removals)\n",
    "\n",
    "print \"\\n ----All Experiments Finisheds ---- \\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Failure\n",
    "\n",
    "Below we plot the results from the failure experiments above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting stuff...\n",
    "\n",
    "#values on x axis\n",
    "xvalues = [(float(x)/float(NetworkSize)) * 20 for x in range(len(er_ave_diameters))]\n",
    "\n",
    "#size of figure to plot\n",
    "fig_size= [18,13]\n",
    "\n",
    "#tell matplotlib some key parameters\n",
    "plt.rcParams.update({'font.size': 20, \"figure.figsize\": fig_size})\n",
    "\n",
    "# Plot diameters of both graphs.\n",
    "plt.plot(xvalues, er_ave_diameters, '--or', xvalues, ba_ave_diameters, '--xb')\n",
    "\n",
    "#plot legend details\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "#set x and y labels of plots, and define plot title\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('diameter')\n",
    "plt.title('Failures on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "\n",
    "#display the plot to screen\n",
    "plt.show()\n",
    "\n",
    "# Plot average path length\n",
    "plt.plot(xvalues, er_ave_path_lengths, '--or', xvalues, ba_ave_path_lengths, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('<l>')\n",
    "plt.title('Failures on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "plt.show()\n",
    "\n",
    "# Plot fraction of nodes in giant component\n",
    "plt.plot(xvalues, er_ave_S, '--or', xvalues, ba_ave_S, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('S')\n",
    "plt.title('Failures on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attack Experiments\n",
    "\n",
    "Now we will run degree-based attacks on the networks, where we remove the nodes with the highest degree first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed if we just want to rerun this cell and not have to create the networks again after we destroy them\n",
    "er_networks = copy.deepcopy(orig_er_networks)\n",
    "ba_networks = copy.deepcopy(orig_ba_networks)\n",
    "\n",
    "er_ave_diameters, er_ave_path_lengths, er_ave_S = experiments(er_networks, num_removals, run_fail=False)\n",
    "ba_ave_diameters, ba_ave_path_lengths, ba_ave_S = experiments(ba_networks, num_removals, run_fail=False)\n",
    "        \n",
    "print \"--Experiments Finished--\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting attacks\n",
    "\n",
    "Now we plot graphs showing the attacks on both networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plotting stuff...see above example, it's the same!\n",
    "xvalues = [(float(x)/float(NetworkSize)) * 20 for x in range(len(er_ave_diameters))]\n",
    "fig_size= [18,13]\n",
    "plt.rcParams.update({'font.size': 20, \"figure.figsize\": fig_size})\n",
    "\n",
    "# Plot diameter\n",
    "plt.plot(xvalues, er_ave_diameters, '--or', xvalues, ba_ave_diameters, '--xb')\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('diameter')\n",
    "plt.title('Attacks on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.show()\n",
    "\n",
    "# Plot average path length\n",
    "plt.plot(xvalues, er_ave_path_lengths, '--or', xvalues, ba_ave_path_lengths, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('<l>')\n",
    "plt.title('Attacks on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "plt.show()\n",
    "\n",
    "# Plot fraction of nodes in giant component\n",
    "plt.plot(xvalues, er_ave_S, '--or', xvalues, ba_ave_S, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='ER')\n",
    "blue_patch = mpatches.Patch(color='blue', label='BA')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('S')\n",
    "plt.title('Attacks on Erdös-Reynéi & Barabási-Albert Networks size ' + str(NetworkSize))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Network\n",
    "\n",
    "Now we can do the same experiments with the Airline Network from the previous class. We will ignore edge direction in this case, as direction can complicate the component definitions. This may take some time as the airline network is large has over 3000 nodes and nearly 40000 edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5108bff7d0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mNetworkSize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0manf_ave_diameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manf_ave_path_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manf_ave_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetworkSize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_fail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_every_X_removals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mana_ave_diameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mana_ave_path_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mana_ave_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mG_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNetworkSize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_fail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasure_every_X_removals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiments' is not defined"
     ]
    }
   ],
   "source": [
    "with open('edgelist.csv', 'rb') as file_handle:\n",
    "    next(file_handle, '')   # skip the header line (NOTE the first list in the CSV file doesn't contain an edge)\n",
    "    G = nx.read_edgelist(file_handle, delimiter=',',\n",
    "                         nodetype=str, data=(('weight', float),), encoding=\"utf-8\")\n",
    "G_c = G.copy()\n",
    "NetworkSize = G.order()\n",
    "\n",
    "anf_ave_diameters, anf_ave_path_lengths, anf_ave_S = experiments([G], int(NetworkSize * 0.8), run_fail=True, measure_every_X_removals=200)\n",
    "ana_ave_diameters, ana_ave_path_lengths, ana_ave_S = experiments([G_c], int(NetworkSize * 0.8), run_fail=False, measure_every_X_removals=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Airline Network\n",
    "\n",
    "Now we plot the result of the attacks and failures on the airline network. You'll see something interesting regarding the average path length...try to think about some consequences of this finding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size= [18,13]\n",
    "plt.rcParams.update({'font.size': 20, \"figure.figsize\": fig_size})\n",
    "xvalues = [(float(x)/float(NetworkSize)) * 200 for x in range(len(anf_ave_diameters))]\n",
    "\n",
    "# Plot diameter\n",
    "plt.plot(xvalues, anf_ave_diameters, '--or', xvalues, ana_ave_diameters, '--xb')\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('diameter')\n",
    "plt.title('Attacks & Failures on Airline Network Networks size')\n",
    "red_patch = mpatches.Patch(color='red', label='Failures')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Attacks')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.show()\n",
    "\n",
    "# Plot average path length\n",
    "plt.plot(xvalues, anf_ave_path_lengths, '--or', xvalues, ana_ave_path_lengths, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='Failures')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Attacks')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('<l>')\n",
    "plt.title('Attacks & Failures on Airline Network Networks size')\n",
    "plt.show()\n",
    "\n",
    "# Plot fraction of nodes in giant component\n",
    "plt.plot(xvalues, anf_ave_S, '--or', xvalues, ana_ave_S, '--xb')\n",
    "red_patch = mpatches.Patch(color='red', label='Failures')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Attacks')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.xlabel('f')\n",
    "plt.ylabel('S')\n",
    "plt.title('Attacks & Failures on Airline Network Networks size')\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Questions & Further Work\n",
    "\n",
    "If you have your own network data, or you're interested in other networks available online, now is a good time to repeat the robustness experiments on these networks. You can use the code above (for the airline network) to repeat the experiments on other networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
